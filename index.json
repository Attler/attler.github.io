[{"categories":null,"contents":" One of the most important problems in Natural Langugage Understanding (NLU) is context. Not all words are different to each other in the same way, which is why models based on word frequency can perform poorly. Word embeddings such as GLOVE are often used in order to represent the similarities and differences words or tokens. Words that are similar in meaning are represented closer together in the embedding space. Some words though have very different meanings in different contexts. For example, \u0026ldquo;bank\u0026rdquo; may mean the \u0026ldquo;bank\u0026rdquo; of a river (noun), a savings \u0026ldquo;bank\u0026rdquo; (noun), to \u0026ldquo;bank\u0026rdquo; money (verb), or a \u0026ldquo;bank\u0026rdquo; of computers (noun). This is difficult to represent and resolve the ambiguity with embeddings.\nCNN The context of a word is not just determined by what words are around it but also their order and the syntax of the string. In NLU tasks such as text classification input documents are often encoded in to some representation of the whole document. This can be done using Convolutional Neural Networks (CNN) which allows the context of otherwise ambiguous words to be represented in the encoding.\nLSTM Sequence-to-sequence models are often used for abstractive text summarisation tasks. The architecture is made up of an encoder which produces a representation of the input sequence and a decoder that produces an output sequence using this encoding as context. Recurrent Neural Networks (RNN) such as LSTM\u0026rsquo;s are used for the encoders and decoders. This means the decoders input context is fixed at each step of the output generation.\nAttention Attention is a mechanism for generating a unique context vector for each step of the decoder sequence. This means that the encoder does not need to encode all information from the input into a single fixed vector. The context vector for each step of the decoder is a weighted sum of the hidden states of the input sequence. These weights are calculated with a score function taking the hidden states of the encoder and decoder as input. This score represents the how much attention should be given to each token of the input sequence at the current step of the output sequence. Attention allows for a dynamic context representing information over long sequences.\nTransformer The Transformer model removes the need for an RNN by using only self-attention. Each layer of both the encoder and decoder transforms the embedding of each token of the sequence in to a new embedding which better represents the token in its context.\n","permalink":"https://attler.github.io/publications/context-in-nlp/","tags":["NLP","Machine Learning"],"title":"Context in nlp"},{"categories":null,"contents":"I have finally gotten around to setting up my personal website.\nWith some inspiration from Rachel Thomas I have added a blog. I would like to practice more writing and in a way that is publishable.\n","permalink":"https://attler.github.io/publications/my-blog/","tags":["random"],"title":"My first post"}]